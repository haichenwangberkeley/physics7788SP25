{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Workshop 10: Numerical differentiation and integration\n\nApril 18, 2025\n\nDue by 9:00 pm April 22, 2025","metadata":{}},{"cell_type":"markdown","source":"**Submit the PDF version of this notebook to Gradescope to receive a grade for this Workshop.**\n\nPlease complete workshop activities in code cells in this iPython notebook. The activities titled **Practice** are purely for you to explore Python, and no particular output is expected. Some of them have some code written, and you should try to modify it in different ways to understand how it works. Although no particular output is expected at submission time, it is _highly_ recommended that you read and work through the practice activities before or alongside the exercises. However, the activities titled **Exercise** have specific tasks and specific outputs expected. Include comments in your code when necessary. Enter your name in the cell at the top of the notebook. \n\n**The workshop should be submitted on bCourses under the Assignments tab (both the .ipynb and .pdf files).**","metadata":{}},{"cell_type":"markdown","source":"The lecture this week introduced you to the first application of numerical techniques. We will explore the applications to Python in this workshop. ","metadata":{}},{"cell_type":"markdown","source":"## Numerical differentiation","metadata":{}},{"cell_type":"markdown","source":"First, let's do differentiation \"by hand\" using loops, which is illustrative. \n\nThese are examples of the \"brute force\" differentiation. They work well for a smooth vector, i.e. if there is not much \"noise\" on top of the function you are trying to differentiate. ","metadata":{}},{"cell_type":"code","source":"# standard preamble\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def forward_dy(y, x):\n    '''\n        Uses forward differences (see below) to estimate the derivatives at each value of x, \n        except for the last one. The derivative at the last value of x is estimated \n        using a backward difference.\n            dy/dx at x[i] is approximated by (y[i+1] - y[i]) /  (x[i+1] - x[i])\n    '''\n    dyf = [0.0]*len(x)\n    for i in range(len(y)-1):\n        dyf[i] = (y[i+1] - y[i])/(x[i+1]-x[i])\n    \n    #set last element by backwards difference\n    dyf[-1] = (y[-1] - y[-2])/(x[-1] - x[-2])\n    return dyf\n\ndef backward_dy(y, x):\n    '''\n        Uses backward differences (see below) to estimate the derivatives at each value of x, \n        except for the first one. The derivative at the first value of x is estimated \n        using a forward difference.\n            dy/dx at x[i] is approximated by (y[i] - y[i-1]) /  (x[i] - x[i-1])\n    '''\n    \n    dyb = [0.0]*len(x)\n    #set first element by forward difference\n    dyb[0] = (y[0] - y[1])/(x[0] - x[1])\n    for i in range(1,len(y)):\n        dyb[i] = (y[i] - y[i-1])/(x[i]-x[i-1])\n\n    return dyb\n\ndef centered_dy(y, x):\n    '''\n        Uses centered differences (see below) to estimate the derivatives at each value of x, \n        except for the first and last values. The derivative at the first value of x is estimated \n        using a forward difference. The derivative at the last value of x is estimated \n        using a backward difference.\n            dy/dx at x[i] is approximated by (y[i+1] - y[i-1]) / (x[i+1]-x[i-1])\n    '''\n    dyc = [0.0]*len(x)\n    dyc[0] = (y[0] - y[1])/(x[0] - x[1])\n    for i in range(1,len(y)-1):\n        dyc[i] = (y[i+1] - y[i-1])/(x[i+1]-x[i-1])\n    dyc[-1] = (y[-1] - y[-2])/(x[-1] - x[-2])\n\n    return dyc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Exercise 1\n1. Use the functions above to estimate the $f'(x)$ in three ways for\n$$f(x) = \\sin(x)$$\nusing $N = 100$ points in the window $x\\in [0, 2\\pi)$. Calculate the analytical derivative at each point as well. Plot the four curves together (forward derivatives, backward derivatives, centered derivatives, and analytical derivatives). If you have done everything right, they should all agree well with each other. You do not need axis labels, but do add a legend to indicate which curve is which.\n\n1. Plot the difference between result from each estimate method and the result from the analytical method. For example, you should compute `dyf - dy_analytical`,`dyb - dy_analytical`, and `dyc - dy_analytical` and plot all three together. You do not need axis labels, but do add a legend to indicate which curve is which. Which method is most accurate? \n\n1. Vary the number of points $N$ representing the original function (try $N = 10, 100, 1000$ points). How does the precision change (*Hint: look at the maximum/minimum value of the differences you calculated above*).","metadata":{}},{"cell_type":"code","source":"# Code here for Exercise 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Using `numpy.gradient()`","metadata":{}},{"cell_type":"markdown","source":"We can use `numpy.gradient()` to compute numerical derivatives. This function computes the gradient using central differences in the interior and first differences at the boundaries. Here is an example of its use:\n\n```python\nimport numpy as np\nx = np.linspace(0, 2 * np.pi, 100)\ny = np.sin(x)\ndy = np.gradient(y, x)\n```\n\nThe `np.gradient()` function takes the array of function values `y` and the corresponding `x` values as inputs and returns the numerical derivative.","metadata":{}},{"cell_type":"markdown","source":"### Exercise 2\n\n1. Use the `numpy.gradient()` function to estimate the derivative of $\\sin(x)$ like you did above, compute the difference relative to the analytical result, and plot this difference along with the difference you obtained for the centered estimates. Feel free to try changing the spacing of `x` values and see how it impacts your result.\n\n2. Try computing higher-order derivatives by applying `numpy.gradient()` multiple times. Plot your estimates of the second derivative and compare it to the analytical result. Does it behave like you expect?","metadata":{}},{"cell_type":"code","source":"# Updated code for Exercise 2 using numpy.gradient()\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function and its analytical derivative\nx = np.linspace(0, 2 * np.pi, 100)\ny = np.sin(x)\ndy_analytical = np.cos(x)\n\n# Compute numerical derivative using numpy.gradient\ndy_numerical = # Fill in this blank. Search the web and see how gradient() function is used\n\n# Plot the difference between numerical and analytical derivatives\nplt.plot(x, dy_numerical - dy_analytical, label='Difference (numerical - analytical)')\nplt.legend()\nplt.title('Difference between Numerical and Analytical Derivatives')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Define function and derivatives\nx = np.linspace(0, 2 * np.pi, 100)\ny = np.sin(x)\ndy_analytical = np.cos(x)\nd2y_analytical = # What is the second derivative of sin(x)?\n\n# First derivative using numpy.gradient()\ndy_numerical = # Fill in your answer\n\n# Second derivative using numpy.gradient() twice\nd2y_numerical = # Fill in your answer\n\n# Plot difference between first derivative estimates\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(x, dy_numerical - dy_analytical, label='dy (numerical - analytical)')\nplt.title('1st Derivative Difference')\nplt.xlabel('x')\nplt.ylabel('Error')\nplt.legend()\n\n# Plot difference between second derivative estimates\nplt.subplot(1, 2, 2)\nplt.plot(x, d2y_numerical - d2y_analytical, label='d²y (numerical - analytical)', color='orange')\nplt.title('2nd Derivative Difference')\nplt.xlabel('x')\nplt.ylabel('Error')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If your data are very noisy, numerical errors on computed derivatives will be large; derivatives tend to magnify noise. In these cases, you have to employ smoothing techniques, either implicitly by using a multipoint derivative formula, or explicitly by smoothing the data yourself, or taking the derivative of a function that has been fit to the data in the neighborhood you are interested in.\n\nHere is an example of a 4-point centered difference of some noisy data (courtesy http://gilgamesh.cheme.cmu.edu/doc/software/jacapo/9-numerics/9.1-numpy/9.2-integration.html#numerical-differentiation):\n\n$$f'(x_i) = \\frac{f(x_{i-2}) - 8f(x_{i-1}) + 8f(x_{i+1}) - f(x_{i+2})}{12h}$$\n","metadata":{}},{"cell_type":"code","source":"def four_point_dy(y, x):\n# define a function that implements the 4-point centered difference derivative\n    \n    return dy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = np.linspace(0, 2 * np.pi,100)\ny = np.sin(x) + 0.1 * np.random.rand(x.shape[0])\n\ndy_analytical = np.cos(x) # analytical derivative\ndyf = forward_dy(y, x) # forward derivative for comparison\ndy4 = four_point_dy(y, x) # four-point derivative\n\n# Plot the original noisy function\nplt.figure()\nplt.plot(x,y,label='original function')\nplt.title('Sin(x) + noise')\nplt.show()\n\n# Plot the derivatives as computed in different ways\nplt.figure()\nplt.plot(x,dy_analytical,'g',label='analytical derivative')\nplt.plot(x,dyf,'r-',label='2pt-forward diff')\nplt.plot(x,dy4,'k--',lw=2,label='4pt-centered diff')\nplt.legend(loc='upper center')\nplt.title('Estimates of derivative')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Numerical integration\n\nMaterial borrowed and modified from http://www.physics.nyu.edu/pine/pymanual/html/chap9/chap9_scipy.html\n\nWhen a function cannot be integrated analytically, or is very difficult to integrate analytically, one generally turns to numerical integration methods. SciPy has a number of routines for performing numerical integration. Most of them are found in the same scipy.integrate library. See http://docs.scipy.org/doc/scipy-0.14.0/reference/integrate.html for the full reference and documentation\n","metadata":{}},{"cell_type":"markdown","source":"### Single integration\n\nThe function `scipy.integrate.quad()` is the workhorse of SciPy’s integration functions. Numerical integration is sometimes called *quadrature* (see lecture notes), hence the name. It is normally the default choice for performing single integrals of a function $f(x)$ over a given fixed range from $a$ to $b$:\n\n$$\\int_a^b f(x) dx$$","metadata":{}},{"cell_type":"markdown","source":"The simplest way to call this function is as follows: `scipy.integrate.quad(f, a, b)`. The arguments are defined as follows:\n    \n    f: the name of the function that you want to integrate\n    a: the lower limit of integration\n    b: the upper limit of integration\n    \nThe routine uses adaptive quadrature methods to numerically evaluate integrals, meaning it successively refines the subintervals (makes them smaller) until a desired level of numerical precision is achieved. There are optional keyword arguments that you can pass to this function to change what this level of precision is or to set an upper limit on how many subintervals can be made. For a full list of these optional arguments, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html. Typically, the default value of precision (for the quad routine, it is 1e-8) will suffice.\n\nAs an example, let’s integrate a Gaussian function over the range from $-1$ to $1$\n\n$$\\int_{-1}^1 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) dx$$\n\nWe first need to define the function $f(x)=e^{-x^2/2}/\\sqrt{2\\pi}$.\n","metadata":{}},{"cell_type":"code","source":"import scipy.integrate\n\ndef func(x):\n    return np.exp(-x**2/2)/np.sqrt(2*np.pi)\n\nprint(scipy.integrate.quad(func, -1, 1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can see that this gives two outputs. The first is the value of the integral `0.68268`. The second is an estimate of the precision of the answer `7.57937e-15`, which is very good. You can store the two values as follows:","metadata":{}},{"cell_type":"code","source":"# Store the two values\n\nval, err = scipy.integrate.quad(func, -1, 1)\n\n# Or ignore the second value\n\nval, _ = scipy.integrate.quad(func, -1, 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And just for reference, you can also use $\\pm \\infty$ as your integration limits:","metadata":{}},{"cell_type":"code","source":"print(scipy.integrate.quad(func, -np.inf, +np.inf))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Integrating sampled data","metadata":{}},{"cell_type":"markdown","source":"If you don't have a known closed or code-able form for your function--in other words, you just have data--you can use one of the following methods to estimate the integral of the underlying function: `scipy.integrate.trapz()`, `scipy.integrate.simps()`, or `scipy.integrate.romb()`, which are the trapezoid, Simpson rule, and Romberg rule methods for integrating functions. Of course, you can also use these methods to estimate the integrals of known functions like the ones we have evaluated using `scipy.integrate.quad()`.\n\n","metadata":{}},{"cell_type":"code","source":"from scipy import integrate\n\n# Define x and y\nx = np.linspace(-2, 2, 20)\ny = x**2\n\n# Numerical integration\nintegral_trapz = np.trapezoid(y, x)            # Updated from np.trapz\nintegral_simps = integrate.simpson(y, x=x)       # Updated from integrate.simps\nintegral_exact = 16.0 / 3.0\n\n# Print results\nprint(\"Trapezoid rule gives:\\t %.5f\" % integral_trapz)\nprint(\"Simpson's rule gives:\\t %.5f\" % integral_simps)\nprint(\"Exact value:\\t\\t %.5f\" % integral_exact)\n\n# Plot\nplt.plot(x, y, label=\"$f(x) = x^2$\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.title(\"Function $f(x) = x^2$ on [-2, 2]\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Exercise 3\n\nCompute a numerical integral \n\n$$\\int_{-1}^1 \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) dx$$\n\nusing an array of $N$ = 10,100, and 1000 samples, and trapezoid and Simpson methods; compare the precision of these estimates of the integral to what the Scipy quadrature method returns.","metadata":{}},{"cell_type":"code","source":"# Code for Exercise 3","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}